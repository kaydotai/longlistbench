Existing document extraction benchmarks focus on key-value extraction, leaving long-list entity extraction underexplored. Yet business documents such as loss runs, invoices, and itemized bills commonly contain dozens to hundreds of repeated records. We introduce LongListBench, a synthetic benchmark for long-list extraction that pairs ground truth JSON with rendered PDFs and OCR transcripts. The benchmark injects seven document phenomena observed in production: page breaks, multi-row entities, duplicates, large documents, irrelevant tables, multi-column layouts, and merged cells. Across 80 documents (6{,}828 incident rows), zero-shot LLM baselines achieve 81.9\% (Gemini 2.5), 80.0\% (GPT-4o), and 78.1\% (GPT-5.2) field-level F1, with the table format and layout disruptions posing the greatest challenges.